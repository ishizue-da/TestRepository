{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreateMecabDictionary.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishizue-da/TestRepository/blob/master/CreateMecabDictionary.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdc_MFpWH71V",
        "colab_type": "text"
      },
      "source": [
        "# 同義語変換辞書"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URQBwT3FJXdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install importnb\n",
        "!pip install ipdb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UILaKCAH71W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "import pickle\n",
        "from collections import defaultdict\n",
        "from functools import reduce\n",
        "\n",
        "import pandas as pd\n",
        "import ipdb\n",
        "\n",
        "selfDir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
        "sys.path.append(os.path.join(selfDir, '../NLPT/src'))\n",
        "\n",
        "# from JapaneseTextPreProcessor import JapaneseTextPreprocess\n",
        "\n",
        "import importnb\n",
        "with __import__('importnb').Notebook(): \n",
        "    from JapaneseTextPreProcessor import JapaneseTextPreprocess\n",
        "\n",
        "\n",
        "#========================================================\n",
        "# csv形式の用語集を読み込み、用語および同義語対応辞書を作成\n",
        "#\n",
        "# TermListFile : csv形式の用語集\n",
        "# SynonymDict  : 用語および同義語対応辞書\n",
        "# TermColName  : 慣用語文字列\n",
        "#========================================================\n",
        "def makeDictionary(TermListFile, SynonymDict = {}, TermColName = '慣用語'):\n",
        "    #csv形式の用語集を読み込み、用語および同義語対応辞書を作成\n",
        "    \n",
        "    #前処理ライブラリのインスタンス呼び出し\n",
        "    pre = JapaneseTextPreprocess()\n",
        "    \n",
        "    #用語集読み込み\n",
        "    TermListDF = pd.read_csv(TermListFile).fillna(\"\")\n",
        "    \n",
        "    #同義語変換辞書構築\n",
        "    for i,term in enumerate(list(TermListDF['用語'].values)):\n",
        "        if len(term)==0: continue\n",
        "        # カナを全角、英字を小文字、全角英数字を半角、記号文字を半角\n",
        "        term = pre.normalizeHanzen(term).lower()\n",
        "        #用語に含まれる（）内を削除\n",
        "        term = re.sub(r'[(|\\[].*?[)|\\]]', '', term)\n",
        "        #空白\\xa0を削除し、,区切りで用語を分割\n",
        "        #termList = [t for t in term.replace('\\xa0','').split(',') if len(t)>1]\n",
        "        termList = [t for t in re.split('[,・\\n]', term.replace('\\xa0','')) if len(t)>1]\n",
        "        #termList = [pre.replacePunctuations(term, replacer='') for term in termList]\n",
        "        \n",
        "        if len(termList)==0: continue\n",
        "        MainTerm = termList[0]\n",
        "        if MainTerm in SynonymDict:\n",
        "            # すでに存在\n",
        "            if len(termList)>1: SynonymDict[MainTerm] |= set(termList[1:])\n",
        "        else:\n",
        "            SynonymDict[MainTerm] = set([]) if len(termList)==1 else set(termList[1:])\n",
        "        \n",
        "        # 慣用語\n",
        "        synonym = pre.normalizeHanzen(TermListDF[TermColName][i]).lower()\n",
        "        synonym = re.sub(r'[(|\\[].*?[)|\\]]', '', synonym)\n",
        "        synonymList = set([t for t in re.split('[,・\\n]', synonym.replace('\\xa0','')) if len(t)>1])\n",
        "        # すでに登録してあるか確認\n",
        "        if MainTerm in synonymList: synonymList.remove(MainTerm)\n",
        "        \n",
        "        if len(synonymList)>0:\n",
        "            # 用語（MainTerm）に追加\n",
        "            SynonymDict[MainTerm] |= synonymList\n",
        "        \n",
        "        #print(MainTerm, SynonymDict[MainTerm])\n",
        "    return SynonymDict\n",
        "    \n",
        "#=============================================================\n",
        "# 同義語変換辞書のうち、keyとvalueの両方に現れる語をマージ\n",
        "# SynonymDict  : 用語および同義語対応辞書\n",
        "#=============================================================\n",
        "def checkDictConflict(SynonymDict):\n",
        "    #同義語変換辞書のうち、keyとvalueの両方に現れる語を検索\n",
        "\n",
        "    conflict = set(SynonymDict.keys()) & set(reduce(lambda a, b: a | b, SynonymDict.values()))\n",
        "    ipdb.set_trace() # dbg\n",
        "    #print('conflict:', conflict)\n",
        "    mergeTerm = defaultdict(set)\n",
        "    for term in conflict:\n",
        "        #print(term+\":\", SynonymDict[term])\n",
        "        for k,v in SynonymDict.items():\n",
        "            # k=用語、v=慣用語\n",
        "            if term in v:\n",
        "                mergeTerm[term].add(k)\n",
        "                #print(k+\":\", SynonymDict[k])\n",
        "    #keyとvalueの両方に現れる語をマージ\n",
        "    for k,v in mergeTerm.items():\n",
        "        #print('k:',k, SynonymDict[k])\n",
        "        if k in SynonymDict:\n",
        "            merged = False\n",
        "            for repTerm in v:\n",
        "                if repTerm in SynonymDict:\n",
        "                    #print('v:',repTerm, SynonymDict[repTerm])\n",
        "                    SynonymDict[repTerm] |= SynonymDict[k]\n",
        "                    merged = True\n",
        "            if merged: del SynonymDict[k]\n",
        "    # 慣用語の同じものを整理\n",
        "    conflict = set(SynonymDict.keys()) & set(reduce(lambda a, b: a | b, SynonymDict.values()))\n",
        "    \n",
        "    return SynonymDict\n",
        "    \n",
        "#=========================================================================\n",
        "# 同義語変換辞書をmecabのユーザー辞書形式に変換\n",
        "# input :\n",
        "#    SynonymDict : 同義語変換辞書\n",
        "# output :\n",
        "#    <登録したい用語>,<ID>,<ID>,<重み>, <品詞>,<品詞の説明>,<*>,<*>,<活用>,\n",
        "#    <活用形>,<登録したい動詞の原形>,<カタカナ表示>,<カタカナ表記>\n",
        "#    のリストデータ\n",
        "#=========================================================================\n",
        "def transformMecabFormat(SynonymDict):\n",
        "    #作成した同義語変換辞書をmecabのユーザー辞書形式に変換\n",
        "    mecabDict = []\n",
        "    for term, synonyms in SynonymDict.items():\n",
        "        weight = -1 * int(pow(len(term), 1.3))\n",
        "        DictInfo = [term, 1285, 1285, weight, '名詞', '用語集', '*', '*', '*', '*', term, '*', '*']\n",
        "        mecabDict.append(DictInfo)\n",
        "        for synonym in synonyms:\n",
        "            weight = -1 * int(pow(len(synonym), 1.3))\n",
        "            DictInfo = [synonym, 1285, 1285, weight, '名詞', '用語集', '*', '*', '*', '*', term, '*', '*']\n",
        "            mecabDict.append(DictInfo)\n",
        "    return mecabDict\n",
        "    \n",
        "\n",
        "def cleansingPartsCategory(TermListDF, TermsCol='用語'):\n",
        "    #csv形式の機器カテゴリ表をクレンジング\n",
        "    \n",
        "    #前処理ライブラリのインスタンス呼び出し\n",
        "    pre = JapaneseTextPreprocess()\n",
        "    \n",
        "    #クレンジング\n",
        "    for index, row in TermListDF.iterrows():\n",
        "        term = row[TermsCol]\n",
        "        term = pre.normalizeHanzen(term).lower()\n",
        "        #用語に含まれる（）内を削除し、空白\\xa0を削除\n",
        "        term = re.sub(r'[(|\\[].*?[)|\\]]', '', term).replace('\\xa0','')\n",
        "        \n",
        "        TermListDF.at[index, TermsCol] = term\n",
        "        \n",
        "    return TermListDF\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "if __name__ == \"__main__\":\n",
        "    print('start')\n",
        "    TermListFile = os.path.join(selfDir, '../data/火力発電用語ボイラ及び附属装置.csv')\n",
        "    \n",
        "    #csv形式の用語集を読み込み、慣用語→用語変換辞書を作成\n",
        "    SynonymDict = makeDictionary(TermListFile)\n",
        "    SynonymDict = checkDictConflict(SynonymDict)\n",
        "    \n",
        "    #pickle化して保存\n",
        "    with open(TermListFile[:-4]+'.pickle', mode='wb') as f:\n",
        "        pickle.dump(SynonymDict, f)\n",
        "    \n",
        "    with open(os.path.splitext(TermListFile)[0]+'.pickle', mode='rb') as f:\n",
        "        SynonymDict = pickle.load(f)\n",
        "    \n",
        "    #辞書をMecab形式csvに変換\n",
        "    transformMecabFormat(SynonymDict, os.path.splitext(TermListFile)[0])\n",
        "    \n",
        "    print('Dictionary Creation Process was done.')\n",
        "    print('Next: execute under command')\n",
        "    print('/usr/local/libexec/mecab/mecab-dict-index -d /usr/local/lib/mecab/dic/ipadic -u /path/to/userdic.dic -f utf-8 -t utf-8 /path/to/userdic.csv')\n",
        "\"\"\"    \n",
        "    \n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}